# Project: Legislative Topic Tagging
Author: Jehan Bugli

## Overview

This project aims to automate policy area categorization for congressional bills.
It includes scripts for data collection, training, and inference.

This project uses a src layout, where all the code sits!
The module structure (within src) is as follows:

- data_collection: modules for downloading and processing bulk data
    - bulk_data.py: initial collection steps for bill data
    - parsing.py: retrieving bill text contents for use
    - policy_areas.py: collecting policy area tags for use
    - utils/downloads.py: a download utility used in other files for loading XML

- training: modules coordinating training efforts
    - train.py: executes grid searches and saves model artifacts

- app: modules for inference and Streamlit app construction
    - app.py: app construction and execution

- cli: CLI scripts (defined in pyproject.toml) for convenience
    - get_data.py: coordinates bulk data downloads -> tabular input data
    - train_model.py: executes model training
    - run_app.py: runs the Streamlit app

Some important files remain outside of src:

- pyproject.toml: Specifies dependencies, CLI scripts, etc.
- uv.lock: A file generated by the uv package manager to lock dependency versions.


## Local development and use

The following steps are required for local use:

1. Clone the repository and navigate to the 'Code' folder (the root for all items below)

2. Create and activate a virtual environment

3. Install all dependencies
    - Standard: "pip install -e ."
    - With uv: "uv sync"

    [Skip steps 4-5 below for inference-only use]

4. Get data
    - Option 1: Download and process from scratch with the "get-data" command
    - Option 2: Download manually from the [public Google Drive folder](https://drive.google.com/drive/u/1/folders/1MgGqZCqIAeMek3NSPCm-LaztjbprP5ed)

    Once this step is complete, there should be an 'input_data.parquet' file in the 'Code' root.

5. Train the model
    - Use the "train-model" command
        - The script can be run directly at "src/training/train.py"
    - .joblib files should have populated in the desired folder, 'model_artifacts' by default

6. Check that model artifacts exist
    - The training loop will load them in the 'model_artifacts' directory
    - An artifacts folder can be downloaded from the Google Drive link provided earlier

7. Run the app
    - If you saved the artifacts outside of the default 'model_artifacts' directory, specify the path with the 'ARTIFACTS_DIR' environment variable
    - Use the "run-app" command
        - This is identical to "streamlit run src/app/app.py"